{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 10: Testing Explanations II\n",
    "\n",
    "Today is the LAST DAY OF DATA4ALL: **CONGRATULATIONS!!!**\n",
    "\n",
    "In this notebook, you are free to explore any data you'd like in order to make your final explanations for COVID-19 positivity *as convincing as possible*. This notebook is designed for you to use it however you'd like; the sections of this notebook are as follows: \n",
    "1. Loading data and required libraries\n",
    "2. Scatter plots and best-fit lines\n",
    "3. Contingency tables\n",
    "4. Histograms\n",
    "5. $Chi^2$ analysis.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"../imgs/covid_ds.jpeg\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But before you begin, please fill in the following cell! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name_here = \"???\"\n",
    "print(f\"Hello, my name is {your_name_here}, and I am a data scientist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "## 1. Loading data and required libraries. \n",
    "\n",
    "Reference notebook(s): Notebook_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "\n",
    "# Next we load our data into a usable format\n",
    "frame = pd.read_csv(\"../data/cov_chi_with_positivity.csv\")\n",
    "\n",
    "# Drop the missing values\n",
    "frame = frame.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_____________________________________________________________________\n",
    "\n",
    "## The Data Dictionary\n",
    "_____________________________________________________________________\n",
    "\n",
    "`ZIP`: ZIP code\n",
    "\n",
    "**Population**\n",
    "\n",
    "`POP`: Total population \n",
    "\n",
    "`P0_44`: Number of people ages 0 to 44 \n",
    "\n",
    "`P45_64`: Number of people ages 45 to 64: \n",
    "\n",
    "`P65_`: Number of people ages 65 and older \n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**Socio-economic status** \n",
    "\n",
    "`MEDINC`: Median household income \n",
    "\n",
    "`PERNOINS`: Percent without health insurance \n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**Racial/Ethnic neighbourhood types**\n",
    "\n",
    "`PERBLK`: Percent of population that is Black  \n",
    "\n",
    "`PERHISP`: Percent of population that is Hispanic  \n",
    "\n",
    "`PERW`: Percent of population that is White \n",
    "\n",
    "`PERASN`: Percent of population that is Asian \n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**Occupations**\n",
    "\n",
    "`PEROFFTC`: Percent office and telecommute workers\n",
    "\n",
    "`PERHSRV`: Percent healthcare service workers\n",
    "\n",
    "`PERPSRV`: Percent public service workers\n",
    "\n",
    "`PERFOOD`: Percent food service workers\n",
    "\n",
    "`PERCLEAN`: Percent cleaning service workers\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**How people get to work**\n",
    "\n",
    "`PERAUTO`: Percent personal automobile commuters\n",
    "\n",
    "`PERTRAN`: Percent public transportation commuters\n",
    "\n",
    "`PERPEDB`: Percent pedestrian and bike commuters\n",
    "\n",
    "`PERTELE`: Percent telecommuters (work from home)\n",
    "\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**Built environments**\n",
    "\n",
    "`FDTRTPER`: Percent food desert tracts \n",
    "\n",
    "`WS_5`: Hospital accessibility score (lower score = hospitals are farther away)\n",
    "\n",
    "`POPDENS`: Population density (per square meter)  \n",
    "\n",
    "`PERCROWD`: Percent housing units w/ > 1 person per room \n",
    "\n",
    "\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**COVID-19**\n",
    "\n",
    "`CASE4_16`: Cases, total (4/16): \n",
    "\n",
    "`TEST4_16`: Tests, total (4/16)\n",
    "\n",
    "`CASER4_16`: Case Rate (4/16) (per pop.) \n",
    "\n",
    "`TESTR4_16`: Testing Rate (4/16) (per pop.) \n",
    "\n",
    "`POSRATE4_16`: Positivity rate (4/16) (percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to explore the different variables by changing the name inside. \n",
    "# Remove '.head()' to see all of the data!\n",
    "frame['???'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "## 2. Scatter plots and best-fit lines.\n",
    "\n",
    "*Tip: You can also change the y-axis variable to be anything you'd like! It doesn't have to be `POSRATE4_16`* \n",
    "\n",
    "Reference notebook(s): Notebook_3, Notebook_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Visualizing to assist \n",
    "# Generate scatterplots of variables vs. mortality\n",
    "\n",
    "exp_var_to_explore = '???'\n",
    "\n",
    "x = frame[exp_var_to_explore]\n",
    "y = frame['POSRATE4_16']\n",
    "\n",
    "# Put the dots on the plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Here we add a 'line of best fit' that helps us visualize potential correlation!\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "\n",
    "\n",
    "plt.xlabel(exp_var_to_explore)\n",
    "plt.ylabel('COVID-19 Positivity Rate')\n",
    "\n",
    "# Reveal the plot. \n",
    "plt.show()\n",
    "\n",
    "# Now find correlation and p-value. \n",
    "r_val, p_val = pearsonr(x,y)\n",
    "r_squared = r_val**2\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"Correlation p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contingency Tables\n",
    "\n",
    "Reference notebook(s): Notebook_4, Notebook_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|             | below_med_explan | above_med_explan     |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| below_med_outcome      | A       | B   |\n",
    "| above_med_outcome      | C        | D      |\n",
    "\n",
    "Remember that contingency tables show \"groups within groups\". This means we need to convert our quantitative data which has a range of values (e.g. 0-100) to categorical data (e.g. below 50 and above 50). Deciding what our \"cut off\" is to create the two groups is up to us, but a common practice is to use the **median** (middle) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that allows us to visualize our contingency table.\n",
    "\n",
    "def visualize_contingency_table(contingency_table, top_labels, left_labels):\n",
    "    # print(\"\\t\\t  Close | Far \")\n",
    "    print('{:<20s} {:<20s} {:<10s}'.format(top_labels[0], top_labels[1], top_labels[2]))\n",
    "\n",
    "    i = 0\n",
    "    for line in contingency_table:\n",
    "        print('{:<20s} {:<20s} {:<10s}'.format(left_labels[i], str(line[0]), str(line[1])))\n",
    "        i += 1\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the outcome and explanatory variables of your choosing. \n",
    "# Enter the names (as a string, in quotes) of a variable. \n",
    "\n",
    "explan_var = ???\n",
    "outcome_var = ???\n",
    "\n",
    "print(f\"Your explanatory variable: {explan_var}\")\n",
    "print(f\"Your outcome variable: {outcome_var}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we can create separate dataframes for 'below' and 'above' the median explanatory variable\n",
    "\n",
    "median_explan = frame[explan_var].median() # Determine the median value\n",
    "above_med_explan = frame[frame[explan_var] > median_explan] # Data frame containing all regions with above median explanatory variable value\n",
    "below_med_explan = frame[frame[explan_var] <= median_explan]  # The rest of the data frames (below median value)\n",
    "\n",
    "# Now we want to count the number of locations with above-and-below median positivity rates (within each)\n",
    "# For simplicity, we label our values according to the table above. \n",
    " \n",
    "med_positivity = frame[outcome_var].median()  # Calculate median positivity (across all of Chicago) here!\n",
    "\n",
    "# For example \"A\" should be the count of all ZIP codes with explanatory variables \n",
    "# below the median value that ALSO have below the median positivity!\n",
    "\n",
    "A_val = below_med_explan[below_med_explan[outcome_var] < med_positivity].shape[0]\n",
    "B_val = above_med_explan[above_med_explan[outcome_var] < med_positivity].shape[0]\n",
    "C_val = below_med_explan[below_med_explan[outcome_var] > med_positivity].shape[0]\n",
    "D_val = above_med_explan[above_med_explan[outcome_var] > med_positivity].shape[0]\n",
    "\n",
    "# Place the variables for each of the counts in the contingency table and run the function to create it. \n",
    "\n",
    "left_labels = [f'below_med_{outcome_var}', f'above_med_{outcome_var}']\n",
    "top_labels = [\" \", f'below_med_{explan_var}', f'above_med_{explan_var}']\n",
    "\n",
    "contingency_table = [\n",
    "    [A_val, B_val], \n",
    "    [C_val, D_val]\n",
    "]\n",
    "\n",
    "visualize_contingency_table(contingency_table, top_labels, left_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## 4. Histograms\n",
    "Reference notebook(s): Notebook_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first translate our contingency variables from the previous section into something more 'readable'\n",
    "\n",
    "low_pos_low_explan = A_val  # low positivity, low explanatory variable\n",
    "low_pos_high_explan = B_val   # low positivity, high explanatory variable\n",
    "high_pos_low_explan = C_val  # high positivity, low explanatory variable\n",
    "high_pos_high_explan = D_val   # high positivity, high explanatory variable\n",
    "\n",
    "\n",
    "plt.bar(x=[f'low_{explan_var}', f'high_{explan_var}'],\n",
    "        height=[low_pos_low_explan, low_pos_high_explan], color='purple', label='low_positivity')\n",
    "\n",
    "plt.bar(x=[f'_low_{explan_var}', f'_high_{explan_var}'],\n",
    "        height=[high_pos_low_explan, high_pos_high_explan], color='gold', label='high_positivity')\n",
    "\n",
    "plt.ylabel(\"Number of Neighborhoods\")\n",
    "\n",
    "plt.title(f\"Neighborhood count grouped by positivity rate and {explan_var}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "## 5. $Chi^2$ Analysis\n",
    "\n",
    "Reference notebook(s): Notebook_4, Notebook_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# Now let us get our p-value! \n",
    "# ... when doing data science in Python, it is common convention to use\n",
    "#.    \"_\" characters to mark variables whose values we don't need. \n",
    "chi_square, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-Square value: {chi_square}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create as many cells as you want here (or anywhere)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/pencil.png\" alt=\"Drawing\" align=left style=\"width: 20px;\"/> <font size=\"4\">**Journal 10:** Reflect </font>\n",
    "\n",
    "**Based on your analysis, what is your central explanation for why Covid-19 impacted some communities in Chicago more than others? Try to package this into a clear and concise claim.**\n",
    "\n",
    "> Write your answer here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
