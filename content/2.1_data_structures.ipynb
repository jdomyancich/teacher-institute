{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Pandas and DataFrames\n",
    "\n",
    "Pandas is a powerful Python library that is essential for data science and analysis. It provides high-performance, easy-to-use data structures, the most important of which is the DataFrame. You can think of a DataFrame as a smart, programmable spreadsheet, like Excel or Google Sheets, but with the full power of Python behind it.\n",
    "\n",
    "Here we'll look into the structure of a dataframe and walk through the most critical first steps to take immediately after loading a dataset into a pandas as a dataframe. Think of this as the initial \"health check\" for your data, a fundamental skill for any data analyst or scientist.\n",
    "\n",
    "Why is this so important? Before you can perform any meaningful analysis, build a model, or create a visualization, you must first understand the data you're working with.  Mastering these first few commands builds a solid foundation for all your future data work and prevents common errors down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "\n",
    "We have already seen a couple examples of **structured data**: lists and dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "\n",
    "Lists are **ordered**, meaning the items are labeled using an **index**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list = [\"eggs\", \"milk\", \"juice\"]   \n",
    "print(grocery_list[???])  # Replace ??? with a number to print \"milk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "\n",
    "Arrays are a special type of list that contains only one data type. This homogeneity allows for more efficient memory usage and faster numerical computations, making them a favorite in scientific computing. Arrays are typically more rigid than lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which list is an array?\n",
    "planet_list = ['mercury', 'venus', 'earth', 'mars', 'jupiter']\n",
    "age_list = [3, 8, 12.0, 38, 40]\n",
    "number_list = [4, 'five', 'ten', 32]\n",
    "\n",
    "type(age_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key takeaway for both lists and arrays is their integer-based indexing. You retrieve an element by its numerical position, starting from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "With **dictionaries**, instead of accessing elements by their numerical index, you access them using a unique key. A dictionary is an unordered collection of key-value pairs. Think of it like a real-world dictionary where you look up a word (the key) to find its definition (the value).\n",
    "\n",
    "This key-based lookup is the primary distinction from lists and arrays. It allows for more intuitive and meaningful data organization. For instance, instead of remembering that the item at index 2 of a list represents a person's age, a dictionary allows you to simply access it with the key 'age'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While lists and arrays store items by their ordered position (index), dictionaries store data as **key-value pairs**. Think of a dictionary like a real-world dictionary where each \"word\" is a unique key, and its \"definition\" is the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = {\n",
    "    \"The Shawshank Redemption\": 9.3,\n",
    "    \"The Godfather\": 9.2,\n",
    "    \"The Dark Knight\": 9.0,\n",
    "    \"Pulp Fiction\": 8.9,\n",
    "    \"Forrest Gump\": 8.8,\n",
    "    \"Inception\": 8.8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tabular Powerhouse: DataFrames\n",
    "Enter the dataframe, a structure that brings together the concepts of lists, arrays, and dictionaries to create a powerful tool for data analysis, most notably implemented in the Pandas library in Python. A dataframe is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). Imagine a spreadsheet, and you have a good mental model of a dataframe.\n",
    "\n",
    "The relationship between dictionaries and dataframes is direct and fundamental. One of the most common ways to create a dataframe is from a dictionary. There are two primary methods. Which do you prefer?:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dictionary of Lists**: You can create a dictionary where the keys represent the column names and the values are lists or arrays of the data for each column. This structure maps directly to the columnar nature of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_planets = {\n",
    "    'Planet': ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter'],\n",
    "    'Order': [1, 2, 3, 4, 5],\n",
    "    'Number of Moons': [0, 0, 1, 2, 79]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **List of Dictionaries:** Alternatively, you can have a list where each element is a dictionary representing a row of data. In this case, the keys of each dictionary become the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_planets = [{\"Planet\": \"Mercury\", \"Order\":1, \"Number of Moons\":0},\n",
    "                  {\"Planet\": \"Venus\", \"Order\": 2, \"Number of Moons\": 0},\n",
    "                  {\"Planet\": \"Earth\", \"Order\": 3, \"Number of Moons\": 1},\n",
    "                  {\"Planet\": \"Mars\", \"Order\": 4, \"Number of Moons\": 2},\n",
    "                  {\"Planet\": \"Jupiter\", \"Order\": 5, \"Number of Moons\": 79}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the proper dictionary (or dictionaries), you can convert it to a Pandas DataFrame using the `DataFrame` function form the Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing the Pandas Library\n",
    "\n",
    "In order to have access to the functions in a library, we have to \"import\" it. This is done with a simple line of code. A common practice it to `import <library name> as <abbreviated name>`. This allows us to define an abbreviation for the library to use whenever we call a function from it instead of typing out the full name of the library every time. The abbreviation is up to you, but most libraries have an agreed upon abbreviation. For examples, most people abbreviate pandas as `pd`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_df = pd.DataFrame(pandas_planets)   # df is a common abbreviation for \"dataframe\"\n",
    "print(planets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also skip the `print()` function when displaying a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pandas dataframe should look familiar. It is how data is structured in spreadsheets like Excel and Google Sheets. The bold numbers on the left are known as the **index** and allow us to number rows. The column names allow us to label and reference individual arrays in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To `print` or not to print?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | `dataframe_name` (in a cell) | `print(dataframe_name)` |\n",
    "|:---|:---|:---|\n",
    "| **Output Format** | Richly formatted HTML table | Plain text |\n",
    "| **Readability** | High, visually organized | Lower, less structured |\n",
    "| **Underlying Call** | Implicit `IPython.display.display()` | Standard `print()` which calls `__str__()` |\n",
    "| **Environment** | Primarily for Jupyter/IPython | Works in any Python environment |\n",
    "| **Cell Behavior** | Only works for the *last* expression in a cell | Can be used anywhere in a cell to print multiple outputs |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading in Data from a .csv File\n",
    "\n",
    "Fortunately, we don't need to build our dataframes from scratch like above. However, knowing how they are structured is useful when working with Pandas. Usually, we will bring in data from an existing file, also known as a **dataset**. The most common file format for raw data is a `.csv` file, short for \"comma separated values\" and it is very easy to convert it into a dataframe:\n",
    "```\n",
    "Planet,Order,Moons\n",
    "Mercury,1,0\n",
    "Venus,2,0\n",
    "Earth,3,1\n",
    "Mars,4,2\n",
    "Jupiter,5,79\n",
    "```\n",
    "\n",
    "`read_csv()` takes a file path as its argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding File Paths for Reading CSVs with Pandas\n",
    "\n",
    "When you use `pd.read_csv('filename.csv')`, you're telling pandas to find a file and load it into a DataFrame. The string you provide inside the parentheses is the **file path**. It's the set of directions from your current location to the file you want.\n",
    "\n",
    "There are two fundamental types of file paths: relative and absolute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Type 1: Relative Paths (Most Common)\n",
    "A relative path describes the location of a file relative to your current working directory. The \"current working directory\" is the folder where your Python script or Jupyter Notebook is currently running. This is the most common and portable way to load local files.\n",
    "\n",
    "**Scenario A: The CSV is in the SAME directory as your notebook**\n",
    "This is the simplest case. You just need to provide the filename.\n",
    "\n",
    "Directory Structure:\n",
    "```\n",
    "/MyProject\n",
    "â”œâ”€â”€ my_notebook.ipynb\n",
    "â””â”€â”€ planets.csv\n",
    "```\n",
    "\n",
    "Code:\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.read_csv('planets.csv')\n",
    "```\n",
    "\n",
    "**Scenario B: The CSV is in a SUBDIRECTORY (a folder inside your current folder)***\n",
    "You need to specify the folder name, followed by a slash, then the filename.\n",
    "\n",
    "Directory Structure:\n",
    "```\n",
    "/MyProject\n",
    "â”œâ”€â”€ my_notebook.ipynb\n",
    "â””â”€â”€ /data\n",
    "    â””â”€â”€ planets.csv\n",
    "```\n",
    "Code:\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/planets.csv')\n",
    "```\n",
    "\n",
    "**Scenario C: The CSV is in a PARENT DIRECTORY (the folder containing your current folder)**\n",
    "You use `..` to go \"up\" one directory level.\n",
    "\n",
    "Directory Structure:\n",
    "```\n",
    "/MyProject\n",
    "â”œâ”€â”€ /notebooks\n",
    "â”‚   â””â”€â”€ my_notebook.ipynb\n",
    "â””â”€â”€ /data\n",
    "    â””â”€â”€ planets.csv\n",
    "```\n",
    "\n",
    "If your current working directory is /notebooks, you would go up one level to /MyProject, then down into /data.\n",
    "\n",
    "Code:\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/planets.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 2: Absolute Paths\n",
    "An absolute path specifies the location of a file starting from the very root of your computer's file system. These paths are long and specific to your machine, which makes them less portable. You should generally avoid them unless necessary.\n",
    "\n",
    "On Windows an absolute path typically starts with a drive letter, like `C:`. The 'r' before the string is important! It creates a \"raw\" string which tells Python to ignore the special meaning of backslashes.\n",
    "\n",
    "`df = pd.read_csv(r'C:\\Users\\YourUsername\\Documents\\MyProject\\data\\planets.csv')`\n",
    "\n",
    "MacOS or Linux starts from the root directory, which is a single forward slash (/).\n",
    "\n",
    "`df = pd.read_csv('/home/yourusername/documents/MyProject/data/planets.csv')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tips & Best Practices\n",
    "\n",
    "- **Check Your Location**: If you're ever unsure about your current working directory, you can find out with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Prefer Relative Paths**: They make your code portable. If you use relative paths and send your project folder to someone else, your code will still work on their machine.\n",
    "\n",
    "- **Use Forward Slashes (/)**: Pandas understands forward slashes on all operating systems, making your code more universal.\n",
    "\n",
    "- **Avoid Spaces in Filenames**: While possible to handle, spaces in file and folder names can sometimes cause issues. Using underscores (_) or hyphens (-) is a safer convention (e.g., my_data_file.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## ðŸ’ª **Exercise** ðŸ’ª\n",
    "\n",
    "1. Look for the `planets.csv` dataset in the file browser to the left to find its location.\n",
    "2. Load the dataset into a Pandas dataframe and assign it to a variable.\n",
    "3. Display the dataframe.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A First Look at a Dataset with Pandas\n",
    "\n",
    "Pandas shines when dealing with large datasets. Now we will look at an authentic dataset of historical global temperatures, courtesy of [Berkeley Earth](https://berkeleyearth.org/about/), which is affiliated with [Lawrence Berkeley National Laboratory](https://www.lbl.gov/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_temps = pd.read_csv(\"data/global_temps_by_city.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a First Look\n",
    "\n",
    "Once you've loaded your dataset into a pandas DataFrame using `pd.read_csv()`, the crucial next step is to get a feel for your data. This initial inspection helps you understand its structure, identify potential issues like missing values, and get a sense of the data's content.\n",
    "\n",
    "Here are the essential dataframe methods and attributes you should use right away. Remember, a dataframe is an **object**, meaning it has certain **methods** associated with it. In pandas (and Python in general), an **attribute** is a piece of data or a characteristic stored on an object, which you access directly by name. Think of it as a property of the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.head()` - View the first few rows\n",
    "This is the most common first step. It shows you the first 5 rows of your DataFrame by default, giving you an immediate look at your columns and the type of data they contain.\n",
    "\n",
    "**Why it's useful**: It's a quick way to confirm your data loaded correctly and to see the column names and data examples without printing the entire (potentially massive) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tempts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.tail()` - View the last few rows\n",
    "Similar to `.head()`, this method shows you the last 5 rows of your DataFrame.\n",
    "\n",
    "**Why it's useful**: This can help you spot any issues with the end of your file, such as summary rows or trailing blank data that might have been loaded incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_temps.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.shape` - Check the dimensions\n",
    "This is an attribute (not a method, so no parentheses) that returns a tuple representing the dimensions of the DataFrame: `(number_of_rows, number_of_columns)`. \n",
    "\n",
    "**Why it's useful**: It tells you exactly how big your dataset is, which is fundamental information for any further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_temps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.info()` - Get a technical summary\n",
    "\n",
    "This method provides a concise technical summary of the dataframe. It's one of the most valuable inspection tools.\n",
    "\n",
    "**Why it's useful**:\n",
    "- Index type: Shows the index type and range.\n",
    "- Column count: Confirms the total number of columns.\n",
    "- Non-Null Count: For each column, it shows how many non-null (non-missing) values there are. This is your first look at missing data! \n",
    "- Dtype: Shows the data type (e.g., `int64`, `float64`, `object`) for each column. An object dtype often means the column contains strings.\n",
    "- Memory usage: Gives you an idea of how much memory the dataframe is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_temps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `AverageTemperature` and `AverageTemperatureUncertainty` columns chave fewer non-nulls than the total entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.describe()` - Generate descriptive statistics\n",
    "\n",
    "This method generates descriptive statistics for the numerical columns in your dataframe.\n",
    "\n",
    "**Why it's useful**: It provides a quick overview of the distribution, central tendency, and spread of your numerical data. You can quickly spot things like outliers (e.g., a huge max value) or unexpected distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_temps.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.columns` - View column names\n",
    "\n",
    "This attribute returns a list of all the column names in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_temps.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## ðŸ’ª **Exercise** ðŸ’ª\n",
    "\n",
    "1. Load the `nba_players_stats.csv` file into a pandas dataframe.\n",
    "2. Inspect the dataframe: Use the methods and attributes described above to inspect your nba_df and answer the following questions:\n",
    "- How many columns (stat categories) are there?\n",
    "- How many entries are there? Is it one entry per player per season?\n",
    "- How are the entries in the dataframe ordered?\n",
    "- Are there any missing values in any of the columns? Which columns?\n",
    "- What is the record for most points scored in a season?\n",
    "- On average, how many years experience does an NBA player have?\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ““ Reflection ðŸ““\n",
    "\n",
    "The data we saw here could also be viewed and inspected with a spreadsheet appplication like Excel or Google Sheets. What are the advantages and disadvantages of these each approach of the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
