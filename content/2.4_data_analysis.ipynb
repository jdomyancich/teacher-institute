{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "In the realm of scientific computing, the ability to effectively analyze and interpret data is paramount. Whether you're working with experimental results, observational data, or simulations, understanding how to systematically process, summarize, and visualize your data is crucial for drawing valid conclusions and advancing scientific knowledge.\n",
    "\n",
    "Pandas has some powerful techniques that are at the heart of quantitative scientific inquiry including grouping data by various attributes, performing sophisticated aggregated analyses to uncover underlying patterns and generate insightful visualizations directly from the data. These skills are fundamental, transferable, and essential for any aspiring scientist or researcher in the modern era of data-driven discovery.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with `groupby()`\n",
    "\n",
    "The `groupby()` method is one of the most powerful and frequently used functions in Pandas for data analysis. It allows you to split your data into groups based on some criteria, apply a function to each group independently, and then combine the results into a single dataframe or series. This process is often referred to as \"split-apply-combine.\"\n",
    "\n",
    "Why groupby() is Essential\n",
    "Imagine you have a dataset of students with their scores on different subjects. You might want to find:\n",
    "- The average score for each subject.\n",
    "- The highest score achieved by students in a particular grade.\n",
    "- The number of students in each class.\n",
    "\n",
    "`groupby()` enables you to answer these types of questions efficiently without writing complex loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it Works (The \"Split-Apply-Combine\" Strategy):\n",
    "\n",
    "1. **Split**: Pandas divides the dataframe into multiple sub-dataframes, where each sub-dataframe contains rows that share the same value for the specified grouping key(s).\n",
    "\n",
    "2. **Apply**: An aggregation function (like `mean()`, `sum()`, `count()`, `max()`, `min()`, `median()`, `std()`, `var()`, or even custom functions) is applied to each individual group.\n",
    "\n",
    "3. **Combine**: The results of the applied function from all the individual groups are then combined back into a single series or dataframe, with the grouping keys becoming the new index.\n",
    "\n",
    "All of this can be done with a single line of code:\n",
    "\n",
    "`df.groupby('split_group')[data_to_be_applied].function_applied_to_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple dataset of student grades to illustrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Student': ['Alice', 'Beth', 'Craig', 'Devon', 'Ellen', 'Frank'],\n",
    "        'Subject': ['Math', 'Math', 'Science', 'Science', 'Math', 'Science'],\n",
    "        'Grade': ['A', 'B', 'A', 'C', 'A', 'B'],\n",
    "        'Score': [90, 85, 78, 92, 95, 88]}\n",
    "\n",
    "students_df = pd.DataFrame(data)\n",
    "\n",
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted the average score for each subject, we would group by `Subject` and apply the `.mean()` function to the `Score` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_by_subject = students_df.groupby('Subject')['Score'].mean()\n",
    "print(\"Average Score by Subject:\")\n",
    "avg_score_by_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted the number of students receiving each letter grade, we would group by `Grade` and apply the `.count()` function to the `Subject` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_per_grade = students_df.groupby('Grade')['Student'].count()\n",
    "print(\"Number of Students per Grade:\")\n",
    "print(students_per_grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 💪 **Exercise** 💪\n",
    "\n",
    "The Periodic Table is not just a chart; it's a treasure trove of structured data about elements. We can use `groupby()` to analyze the elements, their positions on the table and their properties to uncover some of this hidden information.\n",
    "\n",
    "1. Load the `periodic_table.csv` dataset into a Pandas dataframe called `elements_df`. Feel free to do a little exploration of the data to get familiar with it: what are the column names? are there any null values?\n",
    "2. Group the dataframe by `group` (the vertical columns of the periodic table) and calculate the average electronegativity for each group. Which group has the highest average electronegativity? Are there any trends? Print the result.\n",
    "3.  Find the minimum boiling point for each phase of matter (solid, liquid, gas). Print the result.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Analysis with Multiple Statistics\n",
    "\n",
    "Often, we want to see more than just the mean for each group. The `.agg()` method allows you to apply multiple aggregation functions to one or more columns simultaneously, providing a richer statistical summary.\n",
    "\n",
    "Let's group the elements by \"type\" (i.e., metal, nonmetal or semimetal) and get the mean, median, min, max, and standard deviation of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_df = pd.read_csv('data/periodic_table.csv')\n",
    "elements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mass_summary = elements_df.groupby('type')['atomic_mass'].agg(['mean', 'median', 'min', 'max', 'std'])\n",
    "category_mass_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply different aggregations to different columns for each period. This can be a little tricky to understand because there is a lot going on with multiple \"group, apply, combine\" sequences and the creation of a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_properties_summary = elements_df.groupby('period').agg(\n",
    "    avg_atomic_mass = ('atomic_mass', 'mean'),\n",
    "    max_boiling_point = ('boiling_point', 'max'),\n",
    "    min_electronegativity = ('electronegativity', 'min')\n",
    ")\n",
    "\n",
    "period_properties_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's going on here?\n",
    "\n",
    "`elements_df.groupby('period')`: This is the \"Split\" step. It groups your elements_df dataframe into separate sub-groups based on the unique values in the 'period' column.\n",
    "\n",
    "`.agg(...)`: This is the \"Apply\" step, followed by the \"Combine\" step. It allows you to perform multiple aggregation functions simultaneously and gives you the flexibility to rename the resulting aggregated columns to be more descriptive. Inside agg(), you provide keyword arguments where:\n",
    "\n",
    "- The keyword name (e.g., Avg_Atomic_Mass, Max_Boiling_Point, Min_Electronegativity) becomes the name of the new column in the resulting period_properties_summary DataFrame.\n",
    "\n",
    "- The value associated with each keyword is a tuple `(original_column_name, aggregation_function)`.\n",
    "\n",
    "    - `original_column_name` specifies which column from the original `elements_df` the aggregation should be applied to within each group.\n",
    "\n",
    "    - `aggregation_function` specifies the function to apply (e.g., `mean`, `max`, `min`). \n",
    "\n",
    "The result is a new Pandas DataFrame. The index of this new DataFrame will be the unique period values (your grouping key).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 💪 **Exercise** 💪\n",
    "\n",
    "1.  For each `type` of element, calculate the `mean`, `median`, and `count` of `density`. Name the columns in your aggregated result clearly (e.g., 'avg_density', 'median_density', 'count_elements'). Print the result.\n",
    "2.  Using a single `.agg()` call, find the `min` and `max` boiling point for each `group` in the periodic table. Print the result.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📓 Reflection 📓\n",
    "\n",
    "As you are beginning to see, statistics is an essential part of scientific computing. If they're fortunate enough, some students learn these concepts in math class or a dedicated statistics course. However, most students do not see it in their science classes.\n",
    "\n",
    "What have you seen personally with your students and their experience with and ability to apply statistics concepts like probability and descriptive statistics and what would the implications be for doing an activity such as this notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FYI: Saving Your Processed Results\n",
    "\n",
    "After all your analysis, you might want to save your aggregated results or cleaned DataFrame for future use, to share with others, or to load into different software. The `.to_csv()` method is perfect for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary of atomic mass by category to a new CSV file\n",
    "category_mass_summary.to_csv('avg_atomic_mass_by_category.csv')\n",
    "print(\"Saved 'avg_atomic_mass_by_category.csv' successfully!\")\n",
    "\n",
    "# Save the full elements DataFrame (you might want to clean/fill NaNs first if needed)\n",
    "# For this example, let's make a copy and fill some NaNs for demonstration before saving\n",
    "elements_cleaned_for_save = elements_df.copy()\n",
    "elements_cleaned_for_save['electronegativity_pauling'].fillna(elements_cleaned_for_save['electronegativity_pauling'].mean(), inplace=True)\n",
    "\n",
    "elements_cleaned_for_save.to_csv('periodic_table_processed.csv', index=False) # index=False prevents writing the DataFrame index as a column\n",
    "print(\"Saved 'periodic_table_processed.csv' successfully (with filled electronegativity)!\")\n",
    "\n",
    "# You can load it back to confirm\n",
    "loaded_processed_df = pd.read_csv('periodic_table_processed.csv')\n",
    "print(\"\\nLoaded processed file head:\")\n",
    "print(loaded_processed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏆 Congratulations! 🏆\n",
    "\n",
    "Congratulations! You've completed the Pandas Boot Camp. We've covered a lot and you now have the skills to do some important things when working with data including:\n",
    "\n",
    "* **Loading and Inspecting DataFrames:** Bringing your raw data into Python.\n",
    "* **Selecting and Filtering:** Focusing on specific subsets of your data.\n",
    "* **Manipulating Data:** Creating new metrics and cleaning your dataset.\n",
    "* **Grouping and Aggregating:** Summarizing properties across different element categories or periods.\n",
    "* **Saving Results:** Storing your analysis for further use or sharing.\n",
    "\n",
    "This is a very strong foundation for quantitative science. Next, you can dive deeper into dedicated data visualization techniques to tell richer stories with your data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
