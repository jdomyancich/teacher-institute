{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Cleaning\n",
    "\n",
    "Data science is a powerful tool for understanding historical events. It allows us to transform raw information, calculate new metrics, summarize data, and deal with imperfections in historical records. Today, we'll learn key **data manipulation and cleaning** techniques by analyzing one of the most famous datasets in the world: the passenger list from the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the **Titanic dataset** directly from a URL. This is a common and efficient way to access public datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the columns\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often a dataset may not have the most intuitive or descriptive column names. In this case, it is a good idea to provide a \"data dicitonary\":\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "|---|---|---|\n",
    "| Survived | Survival | 0 = No, 1 = Yes |\n",
    "| Pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| Name | Name\n",
    "| Sex | Sex | |\n",
    "| Age | Age | Age in years |\n",
    "| SibSp | # of siblings / spouses aboard the Titanic | |\n",
    "| Parch | # of parents / children aboard the Titanic | |\n",
    "| Ticket | Ticket number | |\n",
    "| Fare | Passenger fare | |\n",
    "| Cabin | Cabin number | |\n",
    "| Embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns\n",
    "\n",
    "Dataset manipulation is often about getting the data in a state that is easier to work with. We will be using the column names a lot so it helps to have names that are easier to work with. Here the columns have capital letters. This can create a lot of headaches as our variables are case-sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `.columns` attribute is a list, we can change it by setting a list of new column names to `dataframe.columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns = ['passengerid', 'survived', 'pclass', 'name', 'sex', 'age',\n",
    "                   'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding New Columns\n",
    "\n",
    "We can often combine some of the columns in some way that yields a new column that creates a variable that will be useful. For example, perhaps we want a column that gives the family size for each passenger. \n",
    "\n",
    "Creating new columns in Pandas is pretty straightforward. We just assign it like a variable:\n",
    "\n",
    "`dataframe['new_column'] = value or calculation`\n",
    "\n",
    "There are several things you can put in the `value or calculation` part, including conditions, but for now, we will simply add the values of the `sibsp` and `parch` columns for each passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add 1 to count the passenger themselves\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Conditional Logic: `np.where()`\n",
    "This allows you to create values based on conditions. For example, we can categorize passengers as as alone or not using our new `family_size` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['was_alone'] = np.where(titanic['family_size'] == 1, 'Yes', 'No')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## ðŸ’ª **Exercise** ðŸ’ª\n",
    "\n",
    "1. Add a new column called `age_group` to `titanic`. For simplicity, if a passenger's `age` is less than 18, they should be labeled 'child'; otherwise, they should be labeled 'adult'.\n",
    "2. The `fare` is in 1912 British Pounds. Let's create a rough estimate for today's value. Create a new column `fare_modern_usd` by multiplying the `Fare` column by 100. Print the head of the updated DataFrame.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics for the Titanic Data\n",
    "\n",
    "Descriptive statistics provide a quick and powerful way to understand the main features of your dataset. By calculating measures like the mean, median, maximum, minimum, and counts, we can get a snapshot of our data's distribution, central tendency, and variability.\n",
    "\n",
    "In this section, we'll apply these essential statistical tools to our Titanic passenger data. This will help us quickly identify key characteristics, such as the average age of passengers, the range of fares paid, and the distribution of genders on board. These initial patterns can then guide more in-depth analysis.\n",
    "\n",
    "The columns in a Pandas dataframe are called \"Pandas Series\". There are many Series methods. Here are the most commonly used:\n",
    "- `.mean()`: average\n",
    "- `.max()`: maximum value in the column\n",
    "- `.counts()`: number of occurences of each unique entry\n",
    "- `.mode()`: returns the most frequent value(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_age = titanic['age'].mean()\n",
    "print(f\"Average age of passenger: {average_age:.2f}\")   # :.2f rounds to 2 dec. places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fare = titanic['fare'].max()\n",
    "print(f\"Maximum Fare Paid: Â£{max_fare:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_counts = titanic['sex'].value_counts()\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mode = titanic['pclass'].mode()\n",
    "print(class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there can be more than one mode, Pandas returns a Series. Here the `0` is the index for that Series (first entry). The `3` is the actual mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## ðŸ’ª **Exercise** ðŸ’ª\n",
    "\n",
    "1. Calculate the survival rate of the passengers, expressed as a percentage. \n",
    "2. Find out how many passengers were in each `pclass` (Passenger Class). Print the counts.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Historical data is rarely perfect. The Titanic dataset is no exception. We have already seen a way to detect \"null\" (missing). Which columns have missing data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Missing Values\n",
    "\n",
    "Missing values are often represented as `NaN` (Not a Number) in Pandas. A simpler way to count how many missing values are in each column is to use the `.isnull()` function. However, it returns a boolean object that is the same size as the dataframe. Therefore, we can link it to the `.sum()` function to add up the number of missing valies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of missing values per column:\")\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Dropping Data\n",
    "\n",
    "Missing data can cause issues with calculations, visualizations, and many data analysis techniques.\n",
    "\n",
    "The `dropna()` function in Pandas is used to **remove rows or columns that contain missing (NaN) values** from a dataframe. It's a quick way to clean up your data, though you need to be cautious as it can lead to significant data loss if many values are missing. `.dropna()` without any arguments can be rather agressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with ANY missing value (most common use)\n",
    "print(f\"Original number of passengers: {len(titanic)}\")\n",
    "\n",
    "titanic_dropped = titanic.dropna()\n",
    "print(f\"Passengers remaining after dropping rows any missing value: {len(titanic_dropped)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with ANY missing value\n",
    "titanic_cleaned_cols = titanic.dropna(axis=1)\n",
    "titanic_cleaned_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows if  the 'age' has missing values\n",
    "titanic_subset_cleaned = titanic.dropna(subset=['age'])\n",
    "len(titanic_subset_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Filling Missing Values (Imputation)\n",
    "\n",
    "A better strategy is often to fill, or *impute*, the missing values. `df.fillna()` allows you to replace `NaN` with a statistical value like the mean, median, or mode.\n",
    "\n",
    "Let's fill the missing `Age` values with the median age of all passengers. We use the median because it's less sensitive to extremely high or low ages (outliers) than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to avoid changing our original DataFrame\n",
    "titanic_filled = titanic.copy()\n",
    "\n",
    "# Calculate the median age\n",
    "median_age = titanic_filled['age'].median()\n",
    "print(f\"The median passenger age is: {median_age:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill missing 'age' values with the median using the `inplace=True` argument, which modifies the dataframe directly, without first assigning it to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_filled['age'].fillna(median_age, inplace=True)\n",
    "\n",
    "print(\"Missing values count after filling age:\")\n",
    "print(titanic_filled.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## ðŸ’ª **Exercise** ðŸ’ª\n",
    "\n",
    "1. Find the most common port of embarkation.\n",
    "2. On the `titanic_filled` DataFrame, fill the missing `embarked` values with the mode you found.\n",
    "3. Print the `isnull().sum()` again to confirm the missing `embarked` NaNs are gone.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ““ Reflection ðŸ““\n",
    "\n",
    "Data cleaning is one of the more frustrating, yet important parts of working with authentic datasets. Do you think it's worth asking your students to do it? Or is it best to provide them pre-cleaned data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
